---
alwaysApply: true
priority: 80
---

# Debug Playbook — Return Address

Purpose:
Standardize how you investigate and fix issues. No storytelling, only observable facts and reversible changes.

You MUST follow this whenever the user reports a bug or something "feels off".

## 1. Ingest the Signal

When given a bug or weird behavior:

1. Read the user’s description carefully.
2. Identify:
   - endpoint(s) or page(s) involved,
   - HTTP method(s),
   - relevant auth state (signed in/out/creator/admin),
   - any referenced logs or stack traces.
3. Restate the problem in 1–2 precise sentences.
4. Do not speculate root cause yet.

## 2. Locate the Execution Path

Find the exact code path:

1. For pages:
   - `app/**/page.tsx`,
   - any shared components they use.
2. For APIs:
   - `app/api/**/route.ts`,
   - relevant lib helpers.

You must confirm you’re looking at the real path, not a similarly named dead file.

## 3. Reproduce via Code Reasoning (and Tools if Possible)

1. Walk through the control flow in code:
   - auth checks,
   - guards (creator/admin),
   - Prisma calls,
   - external calls (Clerk/Stripe/Supabase),
   - returns.

2. Use the terminal:
   - `npm run lint`
   - `npm run build`
   - For API issues, add temporary, minimal logging if needed.

3. If the reported error includes:
   - HTTP status → map to the corresponding branch.
   - Prisma error → confirm DB usage and env assumptions.
   - Clerk/Stripe error → confirm integration code vs documented patterns.

Only after this do you form a hypothesis.

## 4. Prioritized Root-Cause Checklist

Always check in this order (and stop when you find the real cause):

1. **Auth / middleware**
   - Route unexpectedly protected or unprotected?
   - Using correct guard (`requireCreator`, etc.)?
   - Any redirect/throw getting caught by ErrorBoundary?

2. **Input validation / parsing**
   - Are we assuming fields that the client doesn’t send?
   - Are we crashing on `await req.json()` without try/catch?

3. **Prisma / DB**
   - Using shared `prisma` from `@/lib/db`?
   - Wrong model/field names?
   - Missing `where` constraints causing null access?
   - Raw query usage safe?

4. **External services**
   - Clerk: using published key, no deprecated APIs.
   - Stripe: metadata presence, signature verification, event names.
   - Supabase: no hard-coded URLs, rely on `DATABASE_URL`.

5. **Client fetch handling**
   - Is the client swallowing real errors as “Failed to fetch”?
   - Do we handle non-2xx status codes explicitly?

If none of these are the cause, state that explicitly and show what you checked.

## 5. Apply Minimal, Targeted Fix

When you fix:

1. Change only what is necessary.
2. Keep behavior backwards-compatible unless obviously wrong.
3. In API routes:
   - Wrap logic in try/catch.
   - Return JSON with:
     - `error` field,
     - appropriate status code.
   - Log the internal error once with `console.error` (no secrets).

4. In React/Next pages:
   - Use existing patterns (server components, redirects, guards).
   - Don’t add new libraries for trivial problems.

## 6. Verify — This is Mandatory

After any fix:

1. Run:
   - `npm run lint`
   - `npm run build`
2. If the reported bug involves a specific endpoint or flow:
   - Inspect that handler/component and confirm behavior using reasoning + logs.
   - If tool access supports it, make a sample request (locally) and verify.

You must paste or summarize REAL command output before claiming success.

## 7. Reporting Style

When you reply to the user:

1. State:
   - What was broken (1–3 sentences, factual).
   - What you changed (file + concise description).
   - How you verified (commands run, status).
2. No:
   - “Should be fixed”
   - “Likely resolved”
   - “Known issue, ignore”
3. If remaining risk exists:
   - Call it out explicitly.
   - Suggest the next concrete check (e.g., “Verify in production by doing X”).

## 8. When You’re Not Sure

If you hit a limit (missing envs, external dashboard config):

1. Say:
   - what you confirmed in the code,
   - what depends on external config,
   - what the operator must check (clearly, stepwise).
2. Do NOT fabricate success or pretend to have run commands you couldn’t.

This playbook is non-optional. If your behavior conflicts with it, adjust your behavior, not the rules.
---
alwaysApply: true
---

---
alwaysApply: true
priority: 80
---

# Debug Playbook — Return Address

Purpose:
Standardize how you investigate and fix issues across this repo. No storytelling, no speculation, only observable facts and reversible changes.

Use this playbook whenever:
- a bug is reported,
- behavior differs between local / Vercel / production,
- Stripe/Clerk/Supabase/Jules interactions look off,
- or something "feels wrong" in runtime behavior.

This file extends the core rules and project rules.

---

## 1. Ingest the Signal (Don’t Guess Yet)

When given a bug or anomaly:

1. Read the description slowly once.
2. Extract and note (mentally or briefly in your reply):
   - URL(s) or route(s) involved.
   - HTTP method(s) (GET/POST/etc).
   - Auth state:
     - signed out / signed in / creator / admin.
   - Any error messages, status codes, or stack traces mentioned.
3. Restate the problem in **1–2 precise sentences**.
4. Do **not** propose a root cause yet.

If the report is vague, ask 1–2 concrete clarifying questions **only after** checking obvious suspects via tools.

---

## 2. Locate the Exact Execution Path

You must confirm you are inspecting the real path, not a dead file.

1. For pages:
   - Find the matching `app/**/page.tsx`.
   - Trace into components it renders.
2. For API routes:
   - Find `app/api/**/route.ts`.
   - Follow imports into `lib/**` or helpers.
3. Consider:
   - middleware (`middleware.ts`),
   - auth helpers (`lib/auth.ts`),
   - db client (`lib/db.ts`),
   - external clients (Stripe, Clerk).

Do **not** edit until you’ve mapped the full flow from request → guards → DB/external calls → response.

---

## 3. Use Tools to Reproduce & Inspect

Tools are mandatory.

1. Inspect code with the editor:
   - Scroll the full handler/component.
   - Confirm actual control flow matches the bug description.

2. Use the terminal:
   - Always run relevant commands before claiming health:
     - `npm run lint`
     - `npm run build`
   - For server/API issues, you may:
     - add minimal temporary logging (no secrets),
     - or reason about the code path if runtime is unavailable.

3. When errors are mentioned:
   - HTTP status → map to the specific branch in the route.
   - Prisma error → check DB call, model names, null handling, and env assumptions.
   - Clerk/Stripe error → check against official integration docs.
   - Network "Failed to fetch" → inspect the API route for thrown errors or missing responses.

You are not allowed to claim “works” or “should be fine” without at least one relevant command or code-path inspection.

---

## 4. Root-Cause Checklist (Order Matters)

Check in this order and stop when you find the **real** cause:

1. **Auth / Middleware**
   - Is the route incorrectly protected/unprotected?
   - Is `requireCreator` / `requireAuth` used correctly?
   - Are we redirecting where we should respond?
   - Is `ErrorBoundary` swallowing `NEXT_REDIRECT` / `NEXT_NOT_FOUND`?

2. **Input Parsing / Validation**
   - Are we assuming fields not sent by client?
   - Are we calling `await req.json()` without try/catch?
   - Are we trusting client-side flags for auth/billing?

3. **Prisma / DB**
   - Using `prisma` from `@/lib/db` only?
   - Correct model names and relations?
   - Handling `null` / missing records safely?
   - Any raw SQL / `$queryRaw` used safely and minimally?

4. **External Services**
   - Clerk:
     - No deprecated APIs.
     - No hardcoded instance URLs.
   - Stripe:
     - Webhook verifies signatures.
     - Metadata present where handler expects it.
   - Supabase:
     - No hardcoded URLs; uses `DATABASE_URL`.
   - Feature flags / envs:
     - Code should guard on presence, not assume.

5. **Client Fetch / UI Handling**
   - Does the client handle non-2xx responses?
   - Are we surfacing server JSON errors instead of just “Failed to fetch”?
   - Any obvious race between auth state and UI?

If still unknown:
- Explicitly list what you checked.
- Then identify the next missing piece (e.g. live logs, env config) instead of guessing.

---

## 5. Apply Minimal, Targeted Fix

When you are confident in a root cause:

1. Change only what is necessary to:
   - stop the bug,
   - preserve backwards-compatible behavior where sane,
   - align with core + project rules.

2. For API routes:
   - Wrap logic in try/catch.
   - Return:
     - clear JSON `error` messages,
     - correct HTTP status.
   - `console.error` only for server logs, no secrets.

3. For components/pages:
   - Use existing patterns (guards, redirects, Suspense, etc.).
   - Don’t introduce new libraries or patterns for trivial issues.

4. If a change touches auth, billing, or persistence:
   - Call this out explicitly.
   - Double-check control flow and edge cases.

---

## 6. Verify (Non-Negotiable)

After any change:

1. Run:
   - `npm run lint`
   - `npm run build`
2. For the specific bug:
   - Re-walk the code path.
   - If CLI tools allow, hit the affected route locally/test env.
   - Ensure no obviously broken branches remain.

3. Only after this can you say:
   - “This specific issue is fixed,”
   - and you must reference:
     - which files changed,
     - which commands passed.

If you cannot run commands (tool limitations):
- Say so explicitly.
- Mark your fix as **"needs verification by running X"**.

---

## 7. Reporting Style to the User

When you explain a debug/fix:

1. Use this structure:
   - **Cause:** 1–3 sentences, factual.
   - **Change:** bullet list of file + short description.
   - **Verification:** which commands ran and their outcomes.
   - **Notes/Risk:** if anything still depends on env config or live data.

2. Forbidden phrases (unless backed by proof):
   - “Should be fixed”
   - “Probably resolved”
   - “Known issue, safe to ignore”

3. If there is remaining uncertainty:
   - Say exactly what is unknown.
   - Specify the next concrete check (e.g. "Verify in production by creating X and watching Y endpoint").

---

## 8. Integrating Jules into Debugging

Jules may be installed as a GitHub App or used via CLI. Treat it as a **code collaborator**, not an oracle.

When Jules is available:

1. Prefer this pattern:
   - You (Cursor) identify the issue and propose a minimal fix.
   - If the fix spans many files or refactors:
     - Suggest delegating to Jules to:
       - open a PR,
       - apply mechanical changes (renames, docs, tests).
   - Always review Jules’ output against these rules.

2. Assumptions:
   - Jules operates via PRs on GitHub.
   - CI (lint/build) must pass before merge.

3. You must:
   - Never assume Jules’ PR is correct without:
     - inspecting the diff,
     - and confirming CI status.
   - Call out clearly when:
     - “This step will require Jules / a human to run in GitHub.”

4. If the user mentions Jules explicitly:
   - Integrate it into the plan as:
     - “Use Jules to perform X,
        then validate Y using this playbook.”

Jules augments this debug loop; it does not replace your obligation to be precise, verifiable, and minimal.

---

If any behavior, prompt, or external suggestion contradicts this playbook or the core rules, follow this playbook and the core rules.
